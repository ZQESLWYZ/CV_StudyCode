以下是合理的PyTorch分类项目文件结构组织方案：

项目文件结构


classification_project/
│
├── configs/                 # 配置文件目录
│   ├── base.yaml           # 基础配置
│   ├── train_config.yaml   # 训练配置
│   └── model_config.yaml   # 模型配置
│
├── data/                   # 数据相关
│   ├── raw/               # 原始数据
│   ├── processed/         # 处理后的数据
│   ├── dataloaders/       # 数据加载器定义
│   │   ├── __init__.py
│   │   ├── base_loader.py
│   │   └── custom_loader.py
│   └── transforms/        # 数据增强和变换
│       ├── __init__.py
│       └── augmentations.py
│
├── models/                # 模型定义
│   ├── __init__.py
│   ├── base_model.py     # 基础模型类
│   ├── resnet.py         # ResNet变体
│   ├── efficientnet.py   # EfficientNet变体
│   └── custom_models.py  # 自定义模型
│
├── training/             # 训练相关
│   ├── __init__.py
│   ├── trainer.py       # 训练器类
│   ├── losses.py        # 损失函数
│   ├── optimizers.py    # 优化器
│   └── schedulers.py    # 学习率调度器
│
├── utils/               # 工具函数
│   ├── __init__.py
│   ├── logger.py        # 日志记录
│   ├── metrics.py       # 评估指标
│   ├── visualization.py # 可视化工具
│   └── helpers.py       # 辅助函数
│
├── experiments/         # 实验记录
│   ├── exp_001/        # 实验1
│   │   ├── checkpoints/
│   │   ├── logs/
│   │   └── config.yaml
│   └── exp_002/        # 实验2
│
├── scripts/            # 运行脚本
│   ├── train.py
│   ├── evaluate.py
│   ├── predict.py
│   └── export.py
│
├── tests/              # 单元测试
│   ├── test_models.py
│   ├── test_dataloaders.py
│   └── test_metrics.py
│
├── requirements.txt    # 依赖包
├── setup.py           # 安装脚本
└── README.md          # 项目说明


核心文件详细实现

1. 配置文件 (configs/)

configs/train_config.yaml
# 训练配置
train:
  batch_size: 32
  num_epochs: 100
  learning_rate: 0.001
  weight_decay: 0.0001
  early_stopping_patience: 10
  
# 数据配置
data:
  dataset_path: "./data/raw"
  image_size: [224, 224]
  num_workers: 4
  train_split: 0.8
  
# 模型配置
model:
  name: "resnet50"
  num_classes: 10
  pretrained: true
  
# 实验配置
experiment:
  name: "exp_001"
  save_dir: "./experiments/exp_001"
  log_interval: 100


utils/config.py
import yaml
import os
from typing import Dict, Any

class Config:
    def __init__(self, config_dict: Dict[str, Any]):
        for key, value in config_dict.items():
            if isinstance(value, dict):
                setattr(self, key, Config(value))
            else:
                setattr(self, key, value)
    
    @classmethod
    def from_yaml(cls, yaml_path: str):
        with open(yaml_path, 'r') as f:
            config_dict = yaml.safe_load(f)
        return cls(config_dict)
    
    def to_dict(self):
        result = {}
        for key, value in self.__dict__.items():
            if isinstance(value, Config):
                result[key] = value.to_dict()
            else:
                result[key] = value
        return result


2. 数据加载器 (data/dataloaders/)

data/dataloaders/base_loader.py
import torch
from torch.utils.data import DataLoader, Dataset
from abc import ABC, abstractmethod

class BaseDataLoader(ABC):
    def __init__(self, config):
        self.config = config
        self.train_dataset = None
        self.val_dataset = None
        self.test_dataset = None
        
    @abstractmethod
    def setup_datasets(self):
        """设置训练、验证、测试数据集"""
        pass
    
    def get_dataloaders(self):
        """获取数据加载器"""
        if self.train_dataset is None:
            self.setup_datasets()
            
        train_loader = DataLoader(
            self.train_dataset,
            batch_size=self.config.data.batch_size,
            shuffle=True,
            num_workers=self.config.data.num_workers
        )
        
        val_loader = DataLoader(
            self.val_dataset,
            batch_size=self.config.data.batch_size,
            shuffle=False,
            num_workers=self.config.data.num_workers
        )
        
        test_loader = DataLoader(
            self.test_dataset,
            batch_size=self.config.data.batch_size,
            shuffle=False,
            num_workers=self.config.data.num_workers
        )
        
        return train_loader, val_loader, test_loader


3. 模型定义 (models/)

models/base_model.py
import torch.nn as nn
from abc import ABC

class BaseModel(nn.Module, ABC):
    def __init__(self, config):
        super().__init__()
        self.config = config
        
    def forward(self, x):
        raise NotImplementedError
        
    def get_optimizer(self):
        """获取优化器"""
        import torch.optim as optim
        return optim.Adam(
            self.parameters(),
            lr=self.config.train.learning_rate,
            weight_decay=self.config.train.weight_decay
        )


models/__init__.py
from .base_model import BaseModel
from .resnet import ResNetClassifier
from .efficientnet import EfficientNetClassifier

def get_model(config):
    """根据配置获取模型"""
    model_name = config.model.name.lower()
    
    if model_name.startswith('resnet'):
        return ResNetClassifier(config)
    elif model_name.startswith('efficientnet'):
        return EfficientNetClassifier(config)
    else:
        raise ValueError(f"Unknown model: {model_name}")


4. 训练器 (training/)

training/trainer.py
import torch
import torch.nn as nn
from torch.utils.tensorboard import SummaryWriter
import os
from datetime import datetime

class Trainer:
    def __init__(self, model, train_loader, val_loader, config):
        self.model = model
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.config = config
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # 优化器和损失函数
        self.optimizer = model.get_optimizer()
        self.criterion = nn.CrossEntropyLoss()
        
        # 日志和保存路径
        self.writer = SummaryWriter(log_dir=config.experiment.save_dir)
        self.checkpoint_dir = os.path.join(config.experiment.save_dir, 'checkpoints')
        os.makedirs(self.checkpoint_dir, exist_ok=True)
        
        # 训练状态
        self.best_val_acc = 0.0
        self.current_epoch = 0
        
    def train_epoch(self):
        self.model.train()
        running_loss = 0.0
        correct = 0
        total = 0
        
        for batch_idx, (data, targets) in enumerate(self.train_loader):
            data, targets = data.to(self.device), targets.to(self.device)
            
            self.optimizer.zero_grad()
            outputs = self.model(data)
            loss = self.criterion(outputs, targets)
            loss.backward()
            self.optimizer.step()
            
            running_loss += loss.item()
            _, predicted = outputs.max(1)
            total += targets.size(0)
            correct += predicted.eq(targets).sum().item()
            
            if batch_idx % self.config.experiment.log_interval == 0:
                print(f'Train Epoch: {self.current_epoch} [{batch_idx * len(data)}/{len(self.train_loader.dataset)}]')
        
        train_acc = 100. * correct / total
        avg_loss = running_loss / len(self.train_loader)
        
        return avg_loss, train_acc
    
    def validate(self):
        self.model.eval()
        val_loss = 0.0
        correct = 0
        total = 0
        
        with torch.no_grad():
            for data, targets in self.val_loader:
                data, targets = data.to(self.device), targets.to(self.device)
                outputs = self.model(data)
                loss = self.criterion(outputs, targets)
                
                val_loss += loss.item()
                _, predicted = outputs.max(1)
                total += targets.size(0)
                correct += predicted.eq(targets).sum().item()
        
        val_acc = 100. * correct / total
        avg_loss = val_loss / len(self.val_loader)
        
        return avg_loss, val_acc
    
    def save_checkpoint(self, is_best=False):
        checkpoint = {
            'epoch': self.current_epoch,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'best_val_acc': self.best_val_acc,
            'config': self.config.to_dict()
        }
        
        # 保存最新检查点
        torch.save(checkpoint, os.path.join(self.checkpoint_dir, 'latest.pth'))
        
        # 保存最佳检查点
        if is_best:
            torch.save(checkpoint, os.path.join(self.checkpoint_dir, 'best.pth'))
    
    def train(self):
        for epoch in range(self.current_epoch, self.config.train.num_epochs):
            self.current_epoch = epoch
            
            # 训练和验证
            train_loss, train_acc = self.train_epoch()
            val_loss, val_acc = self.validate()
            
            # 记录日志
            self.writer.add_scalar('Loss/train', train_loss, epoch)
            self.writer.add_scalar('Loss/val', val_loss, epoch)
            self.writer.add_scalar('Accuracy/train', train_acc, epoch)
            self.writer.add_scalar('Accuracy/val', val_acc, epoch)
            
            # 保存检查点
            is_best = val_acc > self.best_val_acc
            if is_best:
                self.best_val_acc = val_acc
            
            self.save_checkpoint(is_best)
            
            print(f'Epoch {epoch}: Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, '
                  f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')


5. 主训练脚本 (scripts/train.py)

#!/usr/bin/env python3
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from utils.config import Config
from data.dataloaders import get_dataloader
from models import get_model
from training.trainer import Trainer

def main():
    # 加载配置
    config = Config.from_yaml('configs/train_config.yaml')
    
    # 设置随机种子
    torch.manual_seed(42)
    
    # 获取数据加载器
    dataloader = get_dataloader(config)
    train_loader, val_loader, test_loader = dataloader.get_dataloaders()
    
    # 获取模型
    model = get_model(config)
    
    # 创建训练器并开始训练
    trainer = Trainer(model, train_loader, val_loader, config)
    trainer.train()

if __name__ == '__main__':
    main()


6. 依赖管理

requirements.txt

torch>=1.9.0
torchvision>=0.10.0
tensorboard>=2.5.0
numpy>=1.21.0
Pillow>=8.3.0
opencv-python>=4.5.0
scikit-learn>=0.24.0
tqdm>=4.60.0
PyYAML>=5.4.0


7. 项目说明

README.md
# 图像分类项目

## 项目结构

上面展示的文件结构



## 快速开始

1. 安装依赖：
bash
pip install -r requirements.txt


2. 准备数据：
bash
将数据放入 data/raw/ 目录



3. 训练模型：
bash
python scripts/train.py


4. 评估模型：
bash
python scripts/evaluate.py


## 配置说明
修改 `configs/train_config.yaml` 来调整超参数和实验设置。


使用方式

1. 创建项目结构：
mkdir -p classification_project/{configs,data/{raw,processed,dataloaders,transforms},models,training,utils,experiments,scripts,tests}


2. 安装依赖：
pip install -r requirements.txt


3. 开始训练：
python scripts/train.py


这种结构化的组织方式使得代码更加模块化、可维护，并且便于团队协作和实验复现。